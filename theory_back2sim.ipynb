{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set up plotting style\n",
        "plt.rcParams.update({\n",
        "    \"font.family\": \"serif\",\n",
        "    \"font.size\": 14,\n",
        "    \"figure.dpi\": 300,\n",
        "    \"text.usetex\": False\n",
        "})\n",
        "\n",
        "# ------------------ SIMULATOR ------------------\n",
        "def sir_simulate(beta, gamma, S0=0.99, I0=0.01, R0=0.0, T=50, dt=1.0):\n",
        "    S, I, R = [S0], [I0], [R0]\n",
        "    for _ in range(T-1):\n",
        "        s, i, r = S[-1], I[-1], R[-1]\n",
        "        dS = -beta * s * i\n",
        "        dI = beta * s * i - gamma * i\n",
        "        dR = gamma * i\n",
        "        S.append(s + dS * dt)\n",
        "        I.append(i + dI * dt)\n",
        "        R.append(r + dR * dt)\n",
        "    return np.stack([S, I, R], axis=0)\n",
        "\n",
        "def sample_params(n):\n",
        "    betas = np.random.uniform(0.1, 0.5, size=n)\n",
        "    gammas = np.random.uniform(0.05, 0.2, size=n)\n",
        "    return betas, gammas\n",
        "\n",
        "# ------------------ DATASET ------------------\n",
        "class SIRDataset(Dataset):\n",
        "    def __init__(self, n_samples):\n",
        "        self.X_in, self.X_out, self.theta = [], [], []\n",
        "        betas, gammas = sample_params(n_samples)\n",
        "        for b, g in zip(betas, gammas):\n",
        "            traj = sir_simulate(b, g)\n",
        "            self.X_in.append(torch.tensor(traj[:, :40], dtype=torch.float32))\n",
        "            self.X_out.append(torch.tensor(traj[:, 40:], dtype=torch.float32))\n",
        "            self.theta.append(torch.tensor([b, g], dtype=torch.float32))\n",
        "\n",
        "    def __len__(self): return len(self.X_in)\n",
        "    def __getitem__(self, i):\n",
        "        return {'x': self.X_in[i], 'y': self.X_out[i], 'theta': self.theta[i]}\n",
        "\n",
        "# ------------------ MODEL ------------------\n",
        "class EncoderForecastNet(nn.Module):\n",
        "    def __init__(self, emb_dim=128):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv1d(3, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv1d(32, 64, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv1d(64, 128, 3, padding=1), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1), nn.Flatten(),\n",
        "            nn.Linear(128, emb_dim)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(emb_dim, 128), nn.ReLU(),\n",
        "            nn.Linear(128, 30)  # 3 variables Ã— 10 steps\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        out = self.decoder(z).view(-1, 3, 10)\n",
        "        return out, z\n",
        "\n",
        "# ------------------ TRAINING + ATTRIBUTION ------------------\n",
        "def run_experiment(epochs=3, bandwidths=[0.1, 0.25, 0.5, 1.0]):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    train_ds = SIRDataset(25000)\n",
        "    test_ds = SIRDataset(500)\n",
        "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
        "    model = EncoderForecastNet(emb_dim=128).to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    l2_errors_by_step = []\n",
        "\n",
        "    steps_per_epoch = 5\n",
        "    total_batches = len(train_loader)\n",
        "    batches_per_step = total_batches // steps_per_epoch\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        print(f\"Epoch {ep+1}/{epochs}\")\n",
        "        model.train()\n",
        "        batch_iter = iter(train_loader)\n",
        "\n",
        "        for step in range(steps_per_epoch):\n",
        "            for _ in range(batches_per_step):\n",
        "                try:\n",
        "                    batch = next(batch_iter)\n",
        "                except StopIteration:\n",
        "                    break\n",
        "                x = batch['x'].to(device)\n",
        "                y = batch['y'].to(device)\n",
        "                opt.zero_grad()\n",
        "                y_hat, _ = model(x)\n",
        "                loss = loss_fn(y_hat, y)\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "\n",
        "            # Run attribution at each intra-epoch step\n",
        "            model.eval()\n",
        "            lib = build_library(model, train_ds, size=2000, device=device)\n",
        "            errors = attribution(test_ds, model, lib, n_eval=200, bandwidth=0.1)\n",
        "            mean_error = np.mean(errors)\n",
        "            print(f\"  Step {step+1}/{steps_per_epoch} | L2 Error = {mean_error:.4f}\")\n",
        "            l2_errors_by_step.append(mean_error)\n",
        "\n",
        "    # Final bandwidth sweep\n",
        "    final_lib = build_library(model, train_ds, size=2000, device=device)\n",
        "    mean_errors = []\n",
        "    for bw in bandwidths:\n",
        "        errors = attribution(test_ds, model, final_lib, n_eval=200, bandwidth=bw)\n",
        "        mean_err = np.mean(errors)\n",
        "        print(f\"[Bandwidth {bw}] Mean L2 error = {mean_err:.4f}\")\n",
        "        mean_errors.append(mean_err)\n",
        "\n",
        "    # ----------- Plotting ----------- #\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    x_vals = np.linspace(1, epochs, len(l2_errors_by_step))\n",
        "    axs[0].plot(x_vals, l2_errors_by_step, marker='o', linewidth=2)\n",
        "    axs[0].set_title('Attribution Error During Training', fontsize=14)\n",
        "    axs[0].set_xlabel('Training Epoch', fontsize=13)\n",
        "    axs[0].set_ylabel('Mean L2 Error to True Parameters', fontsize=13)\n",
        "    axs[0].tick_params(axis='both', which='major', labelsize=12)\n",
        "\n",
        "    axs[1].plot(bandwidths, mean_errors, marker='o', linewidth=2)\n",
        "    axs[1].set_title('Bandwidth Sensitivity of Attribution', fontsize=14)\n",
        "    axs[1].set_xlabel('RBF Kernel Bandwidth $h$', fontsize=13)\n",
        "    axs[1].set_ylabel('Mean L2 Error to True Parameters', fontsize=13)\n",
        "    axs[1].tick_params(axis='both', which='major', labelsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"back2sim.pdf\", format=\"pdf\", bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def build_library(model, dataset, size=2000, device='cpu'):\n",
        "    lib = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(size):\n",
        "            sample = dataset[i]\n",
        "            x = sample['x'].unsqueeze(0).to(device)\n",
        "            emb = model.encoder(x).cpu().numpy().flatten()\n",
        "            lib.append({'z': emb, 'theta': sample['theta'].numpy()})\n",
        "    return lib\n",
        "\n",
        "def attribution(test_set, model, lib, n_eval=200, bandwidth=0.5):\n",
        "    errors = []\n",
        "    model.eval()\n",
        "    Z_lib = np.stack([l['z'] for l in lib])\n",
        "    theta_lib = np.stack([l['theta'] for l in lib])\n",
        "\n",
        "    for i in range(n_eval):\n",
        "        sample = test_set[i]\n",
        "        x = sample['x'].unsqueeze(0).to(next(model.parameters()).device)\n",
        "        theta_true = sample['theta'].numpy()\n",
        "        with torch.no_grad():\n",
        "            z = model.encoder(x).cpu().numpy()\n",
        "        dists = pairwise_distances(z, Z_lib)[0]\n",
        "        sims = np.exp(-dists**2 / bandwidth**2)\n",
        "        sims /= sims.sum()\n",
        "        theta_hat = np.sum(sims[:, None] * theta_lib, axis=0)\n",
        "        error = np.linalg.norm(theta_hat - theta_true)\n",
        "        errors.append(error)\n",
        "    return errors\n",
        "\n",
        "run_experiment()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSKZdv5VpPHP",
        "outputId": "d76a434f-a146-43ed-a064-1e9222a44ce1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "  Step 1/5 | L2 Error = 0.0549\n",
            "  Step 2/5 | L2 Error = 0.0315\n",
            "  Step 3/5 | L2 Error = 0.0197\n",
            "  Step 4/5 | L2 Error = 0.0130\n",
            "  Step 5/5 | L2 Error = 0.0111\n",
            "Epoch 2/3\n",
            "  Step 1/5 | L2 Error = 0.0097\n",
            "  Step 2/5 | L2 Error = 0.0080\n",
            "  Step 3/5 | L2 Error = 0.0070\n",
            "  Step 4/5 | L2 Error = 0.0064\n",
            "  Step 5/5 | L2 Error = 0.0058\n",
            "Epoch 3/3\n",
            "  Step 1/5 | L2 Error = 0.0056\n",
            "  Step 2/5 | L2 Error = 0.0055\n",
            "  Step 3/5 | L2 Error = 0.0054\n",
            "  Step 4/5 | L2 Error = 0.0054\n",
            "  Step 5/5 | L2 Error = 0.0054\n",
            "[Bandwidth 0.1] Mean L2 error = 0.0054\n",
            "[Bandwidth 0.25] Mean L2 error = 0.0116\n",
            "[Bandwidth 0.5] Mean L2 error = 0.0206\n",
            "[Bandwidth 1.0] Mean L2 error = 0.0352\n"
          ]
        }
      ]
    }
  ]
}